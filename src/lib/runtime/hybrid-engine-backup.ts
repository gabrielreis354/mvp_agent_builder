import { Agent, AgentNode } from '@/types/agent'
import { ExecutionContext, ExecutionResult } from './engine'
import { UnifiedProcessor } from '@/lib/processors/unified-processor'
import { dynamicOutputGenerator, OutputGenerationConfig, GeneratedOutput } from '@/lib/output/dynamic-output-generator'
import { AIProviderManager } from '@/lib/ai-providers'
import { safeJsonParse } from '@/lib/utils/safe-json'
import { logger } from '@/lib/utils/logger'
import { CachedAIProvider, createCachedAIProvider } from '@/lib/ai/cached-ai-provider'

export interface HybridExecutionOptions {
  uploadedFiles?: File[]
  outputFormat?: 'pdf' | 'docx' | 'csv' | 'html' | 'json'
  outputTemplate?: 'professional' | 'executive' | 'technical' | 'simple'
  deliveryMethod?: 'email' | 'download'
  recipientEmail?: string
}

export interface HybridExecutionResult extends ExecutionResult {
  generatedOutput?: GeneratedOutput
}

export class HybridRuntimeEngine {
  private aiProviderManager!: AIProviderManager
  private cachedAIProvider!: CachedAIProvider

  constructor() {
    this.initializeHybridProviders()
  }

  private initializeHybridProviders() {
    logger.info('Initializing hybrid runtime engine', 'HYBRID_ENGINE')
    
    this.aiProviderManager = new AIProviderManager({
      openai: {
        apiKey: process.env.OPENAI_API_KEY || '',
        organization: process.env.OPENAI_ORG_ID
      },
      anthropic: {
        apiKey: process.env.ANTHROPIC_API_KEY || ''
      },
      google: {
        apiKey: process.env.GOOGLE_AI_API_KEY || ''
      }
    })

    // Inicializar AI Provider com cache
    this.cachedAIProvider = createCachedAIProvider(this.aiProviderManager)
    logger.info('Cached AI Provider initialized', 'HYBRID_ENGINE')
  }

  async executeAgentHybrid(
    agent: Agent, 
    input: any, 
    userId: string,
    options: HybridExecutionOptions = {}
  ): Promise<HybridExecutionResult> {
    console.log(`üîÑ Starting hybrid execution for agent: ${agent.name}`)
    
    // 1. Processar arquivos se fornecidos
    let processedFiles: any[] = []
    if (options.uploadedFiles && options.uploadedFiles.length > 0) {
      console.log(`üìÅ Processing ${options.uploadedFiles.length} uploaded files...`)
      
      const processor = new UnifiedProcessor()
      for (const file of options.uploadedFiles) {
        try {
          const result = await processor.processFile(file)
          if (result.success && result.data) {
            processedFiles.push(result.data)
            console.log(`‚úÖ File processed: ${file.name}`)
          }
        } catch (error) {
          console.warn(`‚ö†Ô∏è Failed to process file ${file.name}:`, error)
        }
      }
    }
    
    // 2. Enriquecer input com dados dos arquivos processados
    const enrichedInput = {
      ...input,
      processedFiles: processedFiles,
      fileData: processedFiles.length > 0 ? processedFiles[0] : null,
      hasFiles: processedFiles.length > 0
    }
    
    // 3. Executar agente com dados enriquecidos
    const executionResult = await this.executeAgent(agent, enrichedInput, userId)
    
    // 4. Gerar output din√¢mico se solicitado
    let hybridResult: HybridExecutionResult = executionResult
    
    if (options.outputFormat && options.outputFormat !== 'json') {
      console.log(`üìÑ Generating ${options.outputFormat} output...`)
      
      try {
        const outputConfig: OutputGenerationConfig = {
          format: options.outputFormat,
          template: options.outputTemplate || 'professional',
          includeCharts: true,
          includeSummary: true,
          branding: true
        }
        
        const generatedOutput = await dynamicOutputGenerator.generateOutput(
          agent,
          executionResult,
          outputConfig
        )
        
        // Anexar output gerado ao resultado
        hybridResult = {
          ...executionResult,
          generatedOutput: generatedOutput
        }
        console.log(`‚úÖ Output generated: ${generatedOutput.filename}`)
        
      } catch (outputError) {
        console.warn('‚ö†Ô∏è Failed to generate output:', outputError)
        // N√£o falhar a execu√ß√£o por causa do output
      }
    }
    
    return hybridResult
  }

  async executeAgent(agent: Agent, input: any, userId: string): Promise<ExecutionResult> {
    const executionId = this.generateExecutionId()
    const context: ExecutionContext = {
      executionId,
      agentId: agent.id || 'unknown',
      userId,
      input,
      variables: { ...input },
      startTime: new Date()
    }

    // Iniciar logging da execu√ß√£o
    logger.startExecution(
      executionId, 
      agent.id || 'unknown', 
      agent.name || 'Unnamed Agent', 
      userId, 
      agent.nodes.length
    )

    try {
      // Ordenar n√≥s topologicamente
      const orderedNodes = this.getExecutionOrder(agent.nodes, agent.edges)
      const nodeObjects = orderedNodes.map(id => agent.nodes.find(n => n.id === id)).filter(Boolean) as AgentNode[]
      
      const nodeResults: Record<string, any> = {}
      
      for (const node of nodeObjects) {
        const nodeStartTime = Date.now()
        
        try {
          const result = await this.executeNode(node, context.variables, context)
          const nodeDuration = Date.now() - nodeStartTime
          
          nodeResults[node.id] = result
          
          // Log sucesso do n√≥
          logger.logNodeExecution(
            executionId,
            node.id,
            node.data?.label || node.type || 'Unknown Node',
            true,
            nodeDuration,
            result
          )
          
          // Atualizar vari√°veis do contexto
          if (result && typeof result === 'object') {
            context.variables = { ...context.variables, ...result }
          }
        } catch (nodeError) {
          const nodeDuration = Date.now() - nodeStartTime
          
          // Log erro do n√≥
          logger.logNodeExecution(
            executionId,
            node.id,
            node.data?.label || node.type || 'Unknown Node',
            false,
            nodeDuration,
            nodeError
          )
          
          throw nodeError
        }
      }

      const executionTime = Date.now() - context.startTime.getTime()
      
      // Log sucesso da execu√ß√£o
      logger.completeExecution(executionId, true)
      
      // Get the result from the last node
      const lastNodeId = nodeObjects[nodeObjects.length - 1]?.id
      const lastNodeResult = nodeResults[lastNodeId]
      
      // If the last node generated HTML content, return it directly
      let finalOutput = lastNodeResult
      logger.debug('Last node result analysis', `EXEC:${executionId}`, { lastNodeResult })
      
      // Check if last node has HTML content
      if (lastNodeResult?.response && typeof lastNodeResult.response === 'string' && lastNodeResult.response.includes('<!DOCTYPE html>')) {
        finalOutput = lastNodeResult.response
        console.log('üéâ HTML content detected in final output!')
      } else {
        // If last node doesn't have HTML, check previous AI nodes for HTML content
        console.log('üîç Searching for HTML in previous AI nodes...')
        for (let i = nodeObjects.length - 2; i >= 0; i--) {
          const nodeId = nodeObjects[i].id
          const nodeResult = nodeResults[nodeId]
          const nodeData = nodeObjects[i].data
          
          console.log(`üîç Checking node ${nodeId} (type: ${nodeData.nodeType})`)
          if (nodeData.nodeType === 'ai') {
            const responseContent = nodeResult?.response
            if (typeof responseContent === 'string') {
              console.log(`üîç AI node ${nodeId} response:`, responseContent.substring(0, 100))
              
              if (responseContent.includes('<!DOCTYPE html>')) {
                finalOutput = responseContent
                console.log(`üéâ HTML content found in AI node ${nodeId}!`)
                break
              }
            } else {
              console.log(`üîç AI node ${nodeId} response type:`, typeof responseContent)
            }
          }
        }
        
        // If no HTML found, use last node result
        if (finalOutput === lastNodeResult) {
          if (lastNodeResult?.response) {
            finalOutput = lastNodeResult.response
            console.log('üìù Non-HTML response detected:', typeof lastNodeResult.response)
          } else {
            console.log('‚ùå No response found in last node result')
          }
        }
      }
      
      return {
        executionId,
        success: true,
        output: finalOutput || context.variables,
        executionTime,
        nodeResults
      }
    } catch (error) {
      const executionTime = Date.now() - context.startTime.getTime()
      const errorMessage = error instanceof Error ? error.message : 'Unknown error'
      
      // Log erro da execu√ß√£o
      logger.completeExecution(executionId, false, errorMessage)
      
      return {
        executionId,
        success: false,
        error: errorMessage,
        executionTime,
        nodeResults: {}
      }
    }
  }

  private generateExecutionId(): string {
    return `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  private getExecutionOrder(nodes: AgentNode[], edges: any[]): string[] {
    // Implementa√ß√£o simples de ordena√ß√£o topol√≥gica
    const nodeMap = new Map(nodes.map(n => [n.id, n]))
    const visited = new Set<string>()
    const result: string[] = []
    
    // Encontrar n√≥s de entrada (sem depend√™ncias)
    const incomingEdges = new Map<string, string[]>()
    edges.forEach(edge => {
      if (!incomingEdges.has(edge.target)) {
        incomingEdges.set(edge.target, [])
      }
      incomingEdges.get(edge.target)!.push(edge.source)
    })
    
    // Come√ßar com n√≥s que n√£o t√™m depend√™ncias
    const startNodes = nodes.filter(n => !incomingEdges.has(n.id))
    
    function visit(nodeId: string) {
      if (visited.has(nodeId)) return
      
      // Visitar depend√™ncias primeiro
      const dependencies = incomingEdges.get(nodeId) || []
      dependencies.forEach(depId => visit(depId))
      
      visited.add(nodeId)
      result.push(nodeId)
    }
    
    // Visitar todos os n√≥s
    nodes.forEach(node => visit(node.id))
    
    return result
  }

  protected async executeNode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    const nodeType = node.data?.nodeType || node.type
    
    console.log(`üîß Executing ${nodeType} node: ${node.data?.label || node.id}`)
    
    switch (nodeType) {
      case 'input':
        return await this.executeInputNode(node, variables, context)
      case 'ai':
        return await this.executeAINode(node, variables, context)
      case 'logic':
        return await this.executeLogicNode(node, variables, context)
      case 'api':
        return await this.executeAPINode(node, variables, context)
      case 'output':
        return await this.executeOutputNode(node, variables, context)
      default:
        console.warn(`Unknown node type: ${nodeType}`)
        return { type: 'unknown', result: variables }
    }
  }

  private async executeInputNode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    console.log('üì• Processing input node...')
    
    // Verificar se h√° arquivo processado nos dados de entrada
    if (variables.hasFile && variables.processedFile) {
      const fileData = variables.processedFile
      
      console.log(`üìÑ File detected: ${fileData.originalName}`)
      console.log(`üìÑ Extracted text length: ${fileData.extractedText?.length || 0} characters`)
      
      return {
        type: 'input',
        hasFile: true,
        fileName: fileData.originalName,
        extractedText: fileData.extractedText,
        extractedData: fileData.extractedData,
        fileMetadata: fileData.metadata,
        userInput: variables
      }
    }
    
    // Fallback: verificar se h√° arquivos processados (formato antigo)
    if (variables.processedFiles && variables.processedFiles.length > 0) {
      const fileData = variables.processedFiles[0]
      
      return {
        type: 'input',
        hasFile: true,
        fileName: fileData.originalName,
        extractedText: fileData.extractedText,
        extractedData: fileData.extractedData,
        fileMetadata: fileData.metadata,
        userInput: variables
      }
    }
    
    // Input normal sem arquivos
    console.log('üì• No file detected, processing text input only')
    return {
      type: 'input',
      hasFile: false,
      userInput: variables
    }
  }

  private async executeAINode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    console.log('ü§ñ Processing AI node...')
    
    const primaryProvider = node.data?.provider || 'openai'
    const primaryModel = node.data?.model || 'gpt-4'
    const prompt = node.data?.prompt || 'Analyze the provided data.'
    
    // Construir contexto para a IA baseado nos dados dispon√≠veis
    let aiContext = prompt
    
    // LIMITAR TEXTO PARA EVITAR EXCEDER LIMITES DE TOKENS
    if (variables.extractedText) {
      const textLength = variables.extractedText.length
      console.log(`üìÑ Processing extracted text: ${textLength} characters`)
      
      // Limitar texto baseado no modelo
      let maxChars = 3000 // Padr√£o conservador
      if (primaryModel.includes('gpt-4')) {
        maxChars = 4000 // GPT-4 tem limite menor
      } else if (primaryModel.includes('gpt-3.5')) {
        maxChars = 8000 // GPT-3.5 pode processar mais
      } else if (primaryModel.includes('claude')) {
        maxChars = 10000 // Claude tem limite maior
      }
      
      // Se o texto √© muito grande, usar apenas uma parte
      if (textLength > maxChars) {
        console.log(`‚ö†Ô∏è Text too long (${textLength} chars), truncating to ${maxChars} chars`)
        const truncatedText = variables.extractedText.substring(0, maxChars)
        aiContext += `\n\nDocumento analisado (primeiros ${maxChars} caracteres de ${textLength}):\n${truncatedText}\n\n[DOCUMENTO TRUNCADO - An√°lise baseada em amostra]`
      } else {
        aiContext += `\n\nDocumento analisado:\n${variables.extractedText}`
      }
    }
    
    // Limitar dados estruturados tamb√©m
    if (variables.extractedData) {
      const dataStr = JSON.stringify(variables.extractedData, null, 2)
      if (dataStr.length > 1000) {
        aiContext += `\n\nDados estruturados (resumo):\n${dataStr.substring(0, 1000)}...`
      } else {
        aiContext += `\n\nDados estruturados:\n${dataStr}`
      }
    }
    
    // üéØ NOVA FUNCIONALIDADE: Adicionar instru√ß√µes customizadas do usu√°rio
    if (variables.customInstructions && variables.customInstructions.trim()) {
      console.log('üìù Adding custom instructions to AI context')
      console.log(`üìù Custom instructions: ${variables.customInstructions.substring(0, 100)}...`)
      
      aiContext += `\n\n=== INSTRU√á√ïES ESPEC√çFICAS DO USU√ÅRIO ===\n${variables.customInstructions.trim()}\n=== FIM DAS INSTRU√á√ïES ===`
      aiContext += `\n\n‚ö†Ô∏è IMPORTANTE: Siga rigorosamente as instru√ß√µes espec√≠ficas acima al√©m do prompt base.`
    }
    
    // N√ÉO incluir dados do usu√°rio completos (podem ser muito grandes)
    // if (variables.userInput) {
    //   aiContext += `\n\nDados do usu√°rio:\n${JSON.stringify(variables.userInput, null, 2)}`
    // }
    
    console.log(`üß† AI context prepared: ${aiContext.length} characters`)
    
    // SISTEMA DE FALLBACK COM M√öLTIPLOS PROVEDORES (modelos atualizados)
    const providers = [
      { provider: primaryProvider, model: primaryModel },
      { provider: 'anthropic', model: 'claude-3-5-sonnet-20241022' }, // Modelo mais recente
      { provider: 'google', model: 'gemini-1.5-flash' }, // Modelo dispon√≠vel e r√°pido
      { provider: 'openai', model: 'gpt-3.5-turbo' },
      { provider: 'openai', model: 'gpt-4o-mini' } // Modelo mais barato e eficiente
    ]
    
    // Remover duplicatas
    const uniqueProviders = providers.filter((item, index, self) =>
      index === self.findIndex((t) => t.provider === item.provider && t.model === item.model)
    )
    
    // Tentar cada provedor em sequ√™ncia
    for (const { provider, model } of uniqueProviders) {
      try {
        console.log(`üöÄ Trying ${provider}/${model}...`)
        
        // Chamar IA com cache inteligente
        const response = await this.cachedAIProvider.generateCompletion(
          provider,
          aiContext,
          model,
          {
            temperature: 0.7,
            max_tokens: 4000,
            useCache: true,
            cacheTTL: 3600, // 1 hora
            userId: context.userId
          }
        )
        
        console.log(`‚úÖ AI response received from ${provider}: ${response.content?.length || 0} characters`)
        
        // Log informa√ß√µes de cache e custo
        if (response.fromCache) {
          logger.info(`AI response served from cache`, `AI:${provider}`, {
            model,
            tokens: response.tokens,
            cost: response.cost,
            duration: response.duration
          })
        } else {
          logger.info(`AI response from real call`, `AI:${provider}`, {
            model,
            tokens: response.tokens,
            cost: response.cost,
            duration: response.duration
          })
        }

        return {
          type: 'ai',
          provider,
          model,
          response: response.content,
          tokens_used: response.tokens || 0,
          success: true,
          fromCache: response.fromCache,
          cost: response.cost,
          duration: response.duration,
          actualProvider: provider // Indicar qual provedor funcionou
        }
        
      } catch (error) {
        console.warn(`‚ö†Ô∏è ${provider}/${model} failed:`, error instanceof Error ? error.message : error)
        // Continuar para o pr√≥ximo provedor
      }
    }
    
    // Se TODOS os provedores falharam, usar fallback inteligente
    console.error('‚ùå All AI providers failed, using intelligent fallback')
    
    // Gerar an√°lise b√°sica baseada no texto extra√≠do
    if (variables.extractedText && variables.extractedText.length > 100) {
      const analysisResponse = this.generateBasicAnalysis(variables.extractedText, prompt)
      
      return {
        type: 'ai',
        provider: 'fallback',
        model: 'basic-analysis',
        response: analysisResponse,
        tokens_used: 0,
        processing_time: 100,
        fallback: true,
        error: 'All AI providers failed'
      }
    }
    
    // √öltimo recurso - retornar erro
    const fallbackResponse = this.generateIntelligentAIFallback(node, variables)
    
    return {
      type: 'ai',
      provider: 'error',
      model: 'none',
      response: fallbackResponse,
      tokens_used: 0,
      processing_time: 0,
      fallback: true,
      error: 'No AI providers available and no text to analyze'
    }
  }

  private async executeLogicNode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    console.log('‚öôÔ∏è Processing logic node...')
    
    const label = node.data?.label || ''
    
    // L√≥gica espec√≠fica baseada no label do n√≥
    if (label.toLowerCase().includes('valida√ß√£o clt')) {
      return this.executeCLTValidation(variables)
    } else if (label.toLowerCase().includes('ranking')) {
      return this.executeRanking(variables)
    } else if (label.toLowerCase().includes('roteamento')) {
      return this.executeRouting(variables)
    } else {
      return this.executeGenericLogic(variables)
    }
  }

  private async executeAPINode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    console.log('üîå Processing API node...')
    
    const label = node.data?.label || ''
    
    // Simular diferentes tipos de API
    if (label.toLowerCase().includes('email')) {
      return this.simulateEmailAPI(variables)
    } else if (label.toLowerCase().includes('hris') || label.toLowerCase().includes('sistema rh')) {
      return this.simulateHRISAPI(variables)
    } else if (label.toLowerCase().includes('folha')) {
      return this.simulatePayrollAPI(variables)
    } else {
      return this.simulateGenericAPI(variables)
    }
  }

  private async executeOutputNode(node: AgentNode, variables: any, context: ExecutionContext): Promise<any> {
    console.log('üì§ Processing output node...')
    
    // Compilar todos os resultados em um output estruturado
    return {
      type: 'output',
      finalResult: variables,
      summary: 'Processamento conclu√≠do com sucesso',
      timestamp: new Date().toISOString(),
      executionId: context.executionId
    }
  }

  // M√©todos auxiliares para l√≥gica espec√≠fica
  private executeCLTValidation(variables: any): any {
    console.log('‚öñÔ∏è Executing CLT validation logic...')
    
    return {
      type: 'logic',
      validation: 'clt',
      result: {
        conforme: true,
        artigos_verificados: ['Art. 442', 'Art. 443', 'Art. 458', 'Art. 477'],
        clausulas_obrigatorias: true,
        periodo_experiencia_valido: true,
        jornada_conforme: true
      },
      recommendations: [
        'Contrato est√° em conformidade com a CLT',
        'Todas as cl√°usulas obrigat√≥rias presentes',
        'Per√≠odo de experi√™ncia dentro do limite legal'
      ]
    }
  }

  private executeRanking(variables: any): any {
    console.log('üìä Executing ranking logic...')
    
    return {
      type: 'logic',
      operation: 'ranking',
      result: {
        total_candidates: 1,
        ranked_list: [
          {
            name: 'Jo√£o Carlos Silva',
            score: 85,
            position: 1,
            recommendation: 'Agendar entrevista'
          }
        ]
      }
    }
  }

  private executeRouting(variables: any): any {
    console.log('üîÄ Executing routing logic...')
    
    return {
      type: 'logic',
      operation: 'routing',
      result: {
        route_to: 'especialista_rh',
        priority: 'medium',
        estimated_response_time: '2 horas'
      }
    }
  }

  private executeGenericLogic(variables: any): any {
    return {
      type: 'logic',
      operation: 'generic',
      result: variables,
      processed: true
    }
  }

  // M√©todos auxiliares para APIs simuladas
  private simulateEmailAPI(variables: any): any {
    console.log('üìß Simulating email API...')
    
    return {
      type: 'api',
      service: 'email',
      result: {
        email_sent: true,
        recipient: variables.userInput?.email || 'usuario@empresa.com',
        subject: 'Relat√≥rio AutomateAI',
        sent_at: new Date().toISOString()
      }
    }
  }

  private simulateHRISAPI(variables: any): any {
    console.log('üë• Simulating HRIS API...')
    
    return {
      type: 'api',
      service: 'hris',
      result: {
        employee_data: {
          id: 'EMP001',
          name: 'Jo√£o Silva',
          department: 'TI',
          position: 'Desenvolvedor',
          start_date: '2023-01-15'
        },
        status: 'active'
      }
    }
  }

  private simulatePayrollAPI(variables: any): any {
    console.log('üí∞ Simulating payroll API...')
    
    return {
      type: 'api',
      service: 'payroll',
      result: {
        salary_data: {
          base_salary: 8500.00,
          benefits: 1200.00,
          deductions: 850.00,
          net_salary: 8850.00
        },
        period: '2024-03'
      }
    }
  }

  private simulateGenericAPI(variables: any): any {
    return {
      type: 'api',
      service: 'generic',
      result: {
        success: true,
        data: variables,
        timestamp: new Date().toISOString()
      }
    }
  }

  private generateBasicAnalysis(extractedText: string, prompt: string): string {
    console.log('üìù Generating basic analysis from extracted text...')
    
    // An√°lise b√°sica do texto extra√≠do
    const wordCount = extractedText.split(/\s+/).length
    const charCount = extractedText.length
    const lines = extractedText.split('\n').length
    
    // Detectar tipo de documento
    const lowerText = extractedText.toLowerCase()
    const isContract = lowerText.includes('contrato') || lowerText.includes('clt') || lowerText.includes('trabalho')
    const isResume = lowerText.includes('curr√≠culo') || lowerText.includes('experi√™ncia') || lowerText.includes('forma√ß√£o')
    const isExpense = lowerText.includes('despesa') || lowerText.includes('reembolso') || lowerText.includes('valor')
    
    // Extrair informa√ß√µes b√°sicas
    const dateMatches = extractedText.match(/\d{1,2}\/\d{1,2}\/\d{4}/g) || []
    const moneyMatches = extractedText.match(/R\$\s*[\d.,]+/g) || []
    const cpfMatches = extractedText.match(/\d{3}\.\d{3}\.\d{3}-\d{2}/g) || []
    const cnpjMatches = extractedText.match(/\d{2}\.\d{3}\.\d{3}\/\d{4}-\d{2}/g) || []
    
    let analysis = `## üìä An√°lise do Documento\n\n`
    analysis += `### Estat√≠sticas Gerais\n`
    analysis += `- **Caracteres:** ${charCount.toLocaleString('pt-BR')}\n`
    analysis += `- **Palavras:** ${wordCount.toLocaleString('pt-BR')}\n`
    analysis += `- **Linhas:** ${lines.toLocaleString('pt-BR')}\n\n`
    
    analysis += `### Tipo de Documento Detectado\n`
    if (isContract) {
      analysis += `‚úÖ **Contrato Trabalhista**\n\n`
      analysis += `### Informa√ß√µes Identificadas\n`
      if (dateMatches.length > 0) {
        analysis += `- **Datas encontradas:** ${dateMatches.slice(0, 5).join(', ')}\n`
      }
      if (moneyMatches.length > 0) {
        analysis += `- **Valores encontrados:** ${moneyMatches.slice(0, 5).join(', ')}\n`
      }
      if (cpfMatches.length > 0) {
        analysis += `- **CPFs encontrados:** ${cpfMatches.length} documento(s)\n`
      }
      if (cnpjMatches.length > 0) {
        analysis += `- **CNPJs encontrados:** ${cnpjMatches.length} empresa(s)\n`
      }
      
      // Buscar cl√°usulas comuns
      analysis += `\n### Cl√°usulas Identificadas\n`
      if (lowerText.includes('sal√°rio')) analysis += `- ‚úÖ Cl√°usula de Sal√°rio\n`
      if (lowerText.includes('jornada')) analysis += `- ‚úÖ Cl√°usula de Jornada de Trabalho\n`
      if (lowerText.includes('f√©rias')) analysis += `- ‚úÖ Cl√°usula de F√©rias\n`
      if (lowerText.includes('rescis√£o')) analysis += `- ‚úÖ Cl√°usula de Rescis√£o\n`
      if (lowerText.includes('benef√≠cio')) analysis += `- ‚úÖ Cl√°usula de Benef√≠cios\n`
      
    } else if (isResume) {
      analysis += `‚úÖ **Curr√≠culo**\n\n`
      analysis += `### Se√ß√µes Identificadas\n`
      if (lowerText.includes('experi√™ncia')) analysis += `- ‚úÖ Experi√™ncia Profissional\n`
      if (lowerText.includes('forma√ß√£o')) analysis += `- ‚úÖ Forma√ß√£o Acad√™mica\n`
      if (lowerText.includes('habilidade')) analysis += `- ‚úÖ Habilidades\n`
      if (lowerText.includes('idioma')) analysis += `- ‚úÖ Idiomas\n`
      
    } else if (isExpense) {
      analysis += `‚úÖ **Relat√≥rio de Despesas**\n\n`
      if (moneyMatches.length > 0) {
        analysis += `### Valores Identificados\n`
        moneyMatches.slice(0, 10).forEach(value => {
          analysis += `- ${value}\n`
        })
      }
    } else {
      analysis += `üìÑ **Documento Gen√©rico**\n\n`
    }
    
    // Adicionar preview do texto
    analysis += `\n### Preview do Documento\n`
    analysis += `\`\`\`\n${extractedText.substring(0, 500)}...\n\`\`\`\n\n`
    
    analysis += `---\n`
    analysis += `*‚ö†Ô∏è Esta √© uma an√°lise b√°sica. Para an√°lise completa com IA, configure as chaves de API dos provedores.*`
    
    return analysis
  }

  private generateIntelligentAIFallback(node: AgentNode, variables: any): string {
    // N√ÉO gerar conte√∫do falso - retornar erro claro
    const prompt = node.data?.prompt || ''
    
    // Se temos texto extra√≠do real, usar ele
    if (variables.extractedText && variables.extractedText.length > 100) {
      return `## An√°lise do Documento\n\nTexto extra√≠do com sucesso (${variables.extractedText.length} caracteres).\n\nAguardando processamento pela IA real...\n\nDados dispon√≠veis:\n- Arquivo: ${variables.fileName || 'documento'}\n- M√©todo: ${variables.method || 'extra√ß√£o'}\n\nERRO: Falha na conex√£o com provedor de IA. Configure as chaves de API.`
    }
    
    // Sem dados reais - retornar erro
    return `## ‚ùå Erro na An√°lise\n\n**Problema identificado:**\n- Nenhum conte√∫do foi extra√≠do do arquivo\n- Arquivo: ${variables.fileName || 'n√£o identificado'}\n- Tipo esperado: ${prompt.includes('contrato') ? 'Contrato PDF' : prompt.includes('curriculo') ? 'Curr√≠culo PDF' : 'Documento'}\n\n**A√ß√£o necess√°ria:**\n1. Verifique se o arquivo foi carregado corretamente\n2. Certifique-se de que √© um PDF v√°lido\n3. Tente novamente com um arquivo diferente\n\n**Status:** FALHA - Sem dados para processar`
  }

  private generateContractAnalysisFallback(variables: any): string {
    // Usar dados reais se dispon√≠veis
    if (variables.extractedText) {
      const preview = variables.extractedText.substring(0, 200)
      return `## An√°lise Parcial do Contrato\n\n**Documento detectado:** ${variables.fileName}\n**Texto extra√≠do:** ${variables.extractedText.length} caracteres\n\n**Pr√©via do conte√∫do:**\n${preview}...\n\n**Status:** Aguardando processamento completo pela IA`
    }
    return `## ‚ùå Erro: Contrato n√£o processado\n\nNenhum arquivo de contrato foi detectado para an√°lise.`
  }

  private generateRecruitmentFallback(variables: any): string {
    if (variables.extractedText) {
      return `## An√°lise Parcial de Curr√≠culo\n\n**Arquivo:** ${variables.fileName}\n**Conte√∫do detectado:** ${variables.extractedText.length} caracteres\n\n**Status:** Processamento de curr√≠culo em andamento...`
    }
    return `## ‚ùå Erro: Curr√≠culo n√£o processado\n\nNenhum arquivo de curr√≠culo foi detectado.`
  }

  private generateExpenseFallback(variables: any): string {
    if (variables.extractedData || variables.extractedText) {
      return `## An√°lise Parcial de Despesas\n\n**Dados detectados:** ${variables.extractedText ? variables.extractedText.length + ' caracteres' : 'Planilha identificada'}\n\n**Status:** Processamento em andamento...`
    }
    return `## ‚ùå Erro: Dados de despesas n√£o encontrados\n\nNenhuma planilha ou documento de despesas foi detectado.`
  }

  private generateHTMLReportFallback(variables: any): string {
    // N√ÉO gerar HTML falso - retornar apenas mensagem de erro
    if (!variables.extractedText && !variables.extractedData) {
      return `<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Erro no Processamento</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; margin: 0; padding: 20px; background-color: #fee2e2; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .header { text-align: center; border-bottom: 3px solid #ef4444; padding-bottom: 20px; margin-bottom: 30px; }
        .header h1 { color: #dc2626; margin: 0; font-size: 28px; }
        .error { background: #fef2f2; border: 1px solid #fecaca; border-radius: 8px; padding: 20px; margin: 20px 0; }
        .error h2 { color: #b91c1c; margin-top: 0; }
        .error ul { margin: 10px 0; padding-left: 20px; }
        .footer { text-align: center; margin-top: 30px; color: #6b7280; font-size: 12px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>‚ùå Erro no Processamento</h1>
            <div>Data: ${new Date().toLocaleDateString('pt-BR')} √†s ${new Date().toLocaleTimeString('pt-BR')}</div>
        </div>
        
        <div class="error">
            <h2>Nenhum arquivo foi processado</h2>
            <p>O sistema n√£o detectou nenhum arquivo ou conte√∫do para an√°lise.</p>
            <ul>
                <li>Verifique se o arquivo foi carregado corretamente</li>
                <li>Certifique-se de que √© um formato suportado (PDF, DOCX, XLSX, etc.)</li>
                <li>Tente novamente com um arquivo diferente</li>
            </ul>
        </div>
        
        <div class="footer">
            <p>AutomateAI - Sistema de Automa√ß√£o Inteligente</p>
        </div>
    </div>
</body>
</html>`
    }
    
    // Se h√° dados reais, gerar relat√≥rio baseado neles
    return this.generateDynamicHTMLReport(variables)
  }
  
  private generateDynamicHTMLReport(variables: any): string {
    const fileName = variables.fileName || 'Documento'
    const extractedLength = variables.extractedText?.length || 0
    const method = variables.extractedData?.method || variables.method || 'processamento'
    const confidence = variables.fileMetadata?.ocrConfidence || 0.95
    const timestamp = new Date().toISOString()
    
    return `<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relat√≥rio de Processamento - ${fileName}</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; margin: 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }
        .container { max-width: 900px; margin: 0 auto; background: white; border-radius: 15px; padding: 40px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); }
        .header { text-align: center; border-bottom: 3px solid #667eea; padding-bottom: 20px; margin-bottom: 30px; }
        .header h1 { color: #2c3e50; margin: 0; }
        .status { background: #10b981; color: white; padding: 5px 15px; border-radius: 20px; display: inline-block; margin-top: 10px; }
        .info-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0; }
        .info-card { background: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 4px solid #667eea; }
        .info-card h3 { color: #2c3e50; margin: 0 0 10px 0; }
        .info-card p { margin: 5px 0; color: #555; }
        .content-preview { background: #f1f5f9; padding: 20px; border-radius: 10px; margin: 20px 0; }
        .content-preview h3 { color: #2c3e50; margin-bottom: 10px; }
        .content-preview pre { white-space: pre-wrap; word-wrap: break-word; color: #444; font-size: 14px; max-height: 300px; overflow-y: auto; }
        .footer { text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #e5e7eb; color: #6b7280; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìÑ Relat√≥rio de Processamento</h1>
            <div class="status">‚úÖ Processamento Conclu√≠do</div>
        </div>
        
        <div class="info-grid">
            <div class="info-card">
                <h3>üìÅ Arquivo Processado</h3>
                <p><strong>Nome:</strong> ${fileName}</p>
                <p><strong>M√©todo:</strong> ${method}</p>
                <p><strong>Confian√ßa:</strong> ${(confidence * 100).toFixed(1)}%</p>
            </div>
            
            <div class="info-card">
                <h3>üìä Estat√≠sticas</h3>
                <p><strong>Caracteres extra√≠dos:</strong> ${extractedLength.toLocaleString('pt-BR')}</p>
                <p><strong>Processado em:</strong> ${new Date(timestamp).toLocaleTimeString('pt-BR')}</p>
                <p><strong>Data:</strong> ${new Date(timestamp).toLocaleDateString('pt-BR')}</p>
            </div>
        </div>
        
        ${extractedLength > 0 ? `
        <div class="content-preview">
            <h3>üìù Pr√©via do Conte√∫do Extra√≠do</h3>
            <pre>${(variables.extractedText || '').substring(0, 500)}${extractedLength > 500 ? '...' : ''}</pre>
        </div>
        ` : ''}
        
        <div class="footer">
            <p>Relat√≥rio gerado automaticamente pelo AutomateAI</p>
            <p>Sistema de Automa√ß√£o Inteligente para RH</p>
        </div>
    </div>
</body>
</html>`
  }

  private generateGenericFallback(variables: any): string {
    if (variables.extractedText || variables.extractedData) {
      return `## Processamento em Andamento\n\nDados detectados: ${variables.extractedText ? variables.extractedText.length + ' caracteres' : 'estruturados'}\nArquivo: ${variables.fileName || 'documento'}\nTimestamp: ${new Date().toISOString()}`
    }
    return `## ‚ùå Erro no Processamento\n\nNenhum dado foi detectado para processar.\nVerifique o arquivo e tente novamente.`
  }
}

export const hybridRuntimeEngine = new HybridRuntimeEngine()
