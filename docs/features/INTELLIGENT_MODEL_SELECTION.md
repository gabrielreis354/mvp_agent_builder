# üß† Sistema Inteligente de Sele√ß√£o de Modelos de IA

**Status:** üìã Planejado  
**Prioridade:** Alta  
**Estimativa:** 3-5 dias  
**Vers√£o alvo:** v2.1.0

---

## üéØ Objetivo

Implementar um sistema inteligente que seleciona automaticamente o melhor modelo de IA baseado no contexto da tarefa, otimizando **custo**, **performance** e **qualidade**.

---

## üîç Problema Atual

Atualmente, o sistema usa modelos fixos ou permite que o usu√°rio escolha manualmente:

- ‚ùå **Ineficiente:** Usa modelos caros para tarefas simples
- ‚ùå **Lento:** Usa modelos lentos quando velocidade √© cr√≠tica
- ‚ùå **Limitado:** N√£o aproveita context windows maiores para documentos grandes
- ‚ùå **Manual:** Usu√°rio precisa entender diferen√ßas entre modelos

---

## ‚úÖ Solu√ß√£o Proposta

### **Sistema de Sele√ß√£o Baseado em Contexto**

```typescript
// Detec√ß√£o autom√°tica do contexto
const context = {
  type: 'document_analysis',        // Tipo de tarefa
  complexity: 'complex',             // Complexidade
  inputSize: 150000,                 // Tamanho em caracteres
  requiresReasoning: true,           // Precisa de racioc√≠nio avan√ßado
  requiresMultimodal: true,          // Precisa processar imagens/PDFs
  budgetPriority: 'balanced'         // cost | balanced | quality
};

// Sele√ß√£o inteligente
const { provider, model } = modelSelector.selectOptimalModel(context);
// ‚Üí google/gemini-1.5-pro (2M context window, √≥timo para docs grandes)
```

---

## üìä Matriz de Decis√£o

### **Por Tipo de Tarefa:**

| Tipo | Modelo Recomendado | Raz√£o |
|------|-------------------|-------|
| **Extra√ß√£o de dados simples** | `gemini-1.5-flash` | Muito r√°pido, barato ($0.075/M) |
| **An√°lise de texto** | `gpt-4o-mini` | Balanceado, boa qualidade |
| **Documentos grandes (>50 p√°ginas)** | `gemini-1.5-pro` | Context window 2M tokens |
| **Racioc√≠nio complexo** | `claude-3-5-sonnet` | Excelente reasoning |
| **Gera√ß√£o de c√≥digo** | `claude-3-5-sonnet` | Especializado em c√≥digo |
| **Conversa√ß√£o r√°pida** | `gpt-4o-mini` ou `claude-haiku` | Baixa lat√™ncia |

### **Por Tamanho de Input:**

| Tamanho | Modelo | Context Window |
|---------|--------|----------------|
| < 4K chars | `gpt-4o-mini` | 128K tokens |
| 4K - 50K | `claude-3-5-haiku` | 200K tokens |
| 50K - 500K | `gemini-1.5-flash` | 1M tokens |
| > 500K | `gemini-1.5-pro` | 2M tokens |

### **Por Prioridade de Budget:**

| Prioridade | Estrat√©gia | Modelos Preferidos |
|------------|------------|-------------------|
| **Cost** | Minimizar custo | `gemini-flash` ‚Üí `gpt-4o-mini` ‚Üí `claude-haiku` |
| **Balanced** | Custo-benef√≠cio | `gpt-4o-mini` ‚Üí `claude-haiku` ‚Üí `gemini-flash` |
| **Quality** | M√°xima qualidade | `claude-sonnet` ‚Üí `gpt-4o` ‚Üí `gemini-pro` |

---

## üèóÔ∏è Arquitetura

### **1. ModelSelector (Core)**

```typescript
// src/lib/ai-providers/model-selector.ts

export class IntelligentModelSelector {
  private modelDatabase: Record<string, Record<string, ModelCapabilities>>;
  
  selectOptimalModel(context: TaskContext): {
    provider: AIProviderType;
    model: string;
    reasoning: string;
  }
  
  detectContext(input: {
    prompt: string;
    fileSize?: number;
    fileType?: string;
  }): TaskContext
}
```

### **2. Integra√ß√£o com AIProviderManager**

```typescript
// src/lib/ai-providers/index.ts

export class AIProviderManager {
  async generateCompletionSmart(
    prompt: string,
    options: {
      context?: Partial<TaskContext>;
      fileSize?: number;
      fileType?: string;
      // ... outros
    }
  ): Promise<AIResponse>
}
```

### **3. Uso no RuntimeEngine**

```typescript
// src/lib/runtime/engine.ts

private async executeAINode(node: AgentNode, input: any): Promise<any> {
  // Detec√ß√£o autom√°tica de contexto
  const taskContext = this.detectTaskType(node, input);
  
  // Sele√ß√£o inteligente
  const response = await this.aiProviderManager.generateCompletionSmart(
    prompt,
    { context: taskContext, fileSize: input.file?.size }
  );
}
```

---

## üìà Benef√≠cios Esperados

### **Otimiza√ß√£o de Custos:**
- ‚úÖ **-60% custo** em tarefas simples (usar flash/mini em vez de pro/sonnet)
- ‚úÖ **-40% custo m√©dio** geral com sele√ß√£o inteligente

### **Melhoria de Performance:**
- ‚úÖ **-50% lat√™ncia** em tarefas simples (modelos r√°pidos)
- ‚úÖ **+200% throughput** com modelos adequados

### **Qualidade:**
- ‚úÖ **+30% qualidade** em tarefas complexas (modelos avan√ßados)
- ‚úÖ **100% sucesso** em docs grandes (context window adequado)

### **UX:**
- ‚úÖ **Zero configura√ß√£o** - usu√°rio n√£o precisa escolher modelo
- ‚úÖ **Transpar√™ncia** - logs explicam escolha do modelo

---

## üß™ Casos de Teste

### **Teste 1: Extra√ß√£o Simples**
```typescript
Input: "Extrair nome e email do texto: Jo√£o Silva - joao@email.com"
Expected: gemini-1.5-flash (r√°pido, barato)
Cost: ~$0.0001
Time: ~500ms
```

### **Teste 2: An√°lise de Contrato (50 p√°ginas)**
```typescript
Input: PDF 150KB + "Analisar conformidade CLT"
Expected: gemini-1.5-pro (context window 2M)
Cost: ~$0.15
Time: ~8s
```

### **Teste 3: Gera√ß√£o de C√≥digo**
```typescript
Input: "Criar fun√ß√£o TypeScript para valida√ß√£o de CPF com testes"
Expected: claude-3-5-sonnet (especializado em c√≥digo)
Cost: ~$0.02
Time: ~3s
```

### **Teste 4: Conversa R√°pida**
```typescript
Input: "Ol√°, como posso ajudar?"
Expected: gpt-4o-mini (baixa lat√™ncia)
Cost: ~$0.0001
Time: ~300ms
```

---

## üìã Checklist de Implementa√ß√£o

### **Fase 1: Core (2 dias)**
- [ ] Criar `src/lib/ai-providers/model-selector.ts`
- [ ] Implementar `ModelCapabilities` database
- [ ] Implementar `selectOptimalModel()`
- [ ] Implementar `detectContext()`
- [ ] Testes unit√°rios

### **Fase 2: Integra√ß√£o (1 dia)**
- [ ] Adicionar `generateCompletionSmart()` ao AIProviderManager
- [ ] Integrar com RuntimeEngine
- [ ] Atualizar RuntimeErrorHandler para usar sele√ß√£o inteligente
- [ ] Logs estruturados

### **Fase 3: Testes (1 dia)**
- [ ] Testes de integra√ß√£o
- [ ] Testes com arquivos reais
- [ ] Valida√ß√£o de custos
- [ ] Benchmarks de performance

### **Fase 4: Documenta√ß√£o (1 dia)**
- [ ] Atualizar COPILOT_PROMPT_V2.md
- [ ] Criar guia de uso
- [ ] Documentar API
- [ ] Exemplos pr√°ticos

---

## üîß Configura√ß√£o

### **Vari√°veis de Ambiente:**

```env
# Feature Flag
ENABLE_INTELLIGENT_MODEL_SELECTION=true

# Budget Priority Global (pode ser sobrescrito por agente)
DEFAULT_BUDGET_PRIORITY=balanced # cost | balanced | quality

# Limites de Custo (opcional)
MAX_COST_PER_REQUEST=1.00 # USD
WARN_COST_THRESHOLD=0.50 # USD
```

### **Por Agente (opcional):**

```typescript
// No AgentNode.data
{
  budgetPriority: 'cost', // For√ßar prioridade de custo
  maxCostPerExecution: 0.10, // Limite de custo
  preferredProvider: 'google' // Prefer√™ncia (n√£o obrigat√≥rio)
}
```

---

## üìä Monitoramento

### **M√©tricas a Coletar:**

```typescript
{
  modelSelections: {
    'gemini-1.5-flash': 450,
    'gpt-4o-mini': 320,
    'claude-3-5-sonnet': 80
  },
  avgCostPerRequest: 0.025,
  avgLatency: 2.3,
  costSavings: 0.45 // vs usar sempre modelos premium
}
```

### **Dashboard:**
- Distribui√ß√£o de modelos usados
- Custo total por per√≠odo
- Economia vs baseline (sempre usar gpt-4)
- Lat√™ncia m√©dia por modelo

---

## üöÄ Roadmap Futuro

### **v2.2.0: Aprendizado**
- Machine learning para melhorar sele√ß√£o baseado em hist√≥rico
- Feedback loop: qualidade do resultado ‚Üí ajuste de sele√ß√£o

### **v2.3.0: Otimiza√ß√£o Avan√ßada**
- Cache de resultados para queries similares
- Batch processing para m√∫ltiplas tarefas
- Streaming inteligente (escolher modelos que suportam)

### **v2.4.0: Multi-Agent**
- Coordena√ß√£o entre m√∫ltiplos modelos
- Especializa√ß√£o: modelo A para extra√ß√£o, modelo B para an√°lise
- Consensus: m√∫ltiplos modelos votam em resultado

---

## üìö Refer√™ncias

- [OpenAI Pricing](https://openai.com/pricing)
- [Anthropic Pricing](https://www.anthropic.com/pricing)
- [Google AI Pricing](https://ai.google.dev/pricing)
- [Context Window Comparison](https://artificialanalysis.ai/models)

---

**√öltima atualiza√ß√£o:** 20/10/2025  
**Respons√°vel:** Equipe de Desenvolvimento  
**Revis√£o:** Pendente
